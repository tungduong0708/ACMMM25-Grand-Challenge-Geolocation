{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13be68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:02:21.012865Z",
     "iopub.status.busy": "2025-05-25T08:02:21.012575Z",
     "iopub.status.idle": "2025-05-25T08:02:27.345903Z",
     "shell.execute_reply": "2025-05-25T08:02:27.345129Z",
     "shell.execute_reply.started": "2025-05-25T08:02:21.012811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (2.4.0+cu124)\n",
      "Requirement already satisfied: torchvision==0.19.0 in /usr/local/lib/python3.11/dist-packages (0.19.0+cu124)\n",
      "Requirement already satisfied: torchaudio==2.4.0 in /usr/local/lib/python3.11/dist-packages (2.4.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.19.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.19.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.19.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.19.0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.19.0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.19.0) (2.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.19.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.19.0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.19.0) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.19.0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.19.0) (2024.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
      "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (3.7.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.4.0+cu124)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj) (2025.4.26)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.20.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install transformers accelerate huggingface_hub pandas optuna pyproj einops geopy matplotlib kaggle  geopandas cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1acad77-8612-43fd-a8e6-31af4daf8bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:02:27.347128Z",
     "iopub.status.busy": "2025-05-25T08:02:27.346910Z",
     "iopub.status.idle": "2025-05-25T08:02:27.520473Z",
     "shell.execute_reply": "2025-05-25T08:02:27.519723Z",
     "shell.execute_reply.started": "2025-05-25T08:02:27.347105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 25 08:02:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0f5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:02:27.522876Z",
     "iopub.status.busy": "2025-05-25T08:02:27.522652Z",
     "iopub.status.idle": "2025-05-25T08:02:54.326862Z",
     "shell.execute_reply": "2025-05-25T08:02:54.326105Z",
     "shell.execute_reply.started": "2025-05-25T08:02:27.522855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfeee56c354439aafd31f17057ed020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7aa254bcbd418f96350d186beddd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "filtered_mp16.tar:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded dataset to /kaggle/working/G3-Original/data/mp16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184d1e88dfb9442aa8c8526aa57d5f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MP16_Pro_filtered.csv:   0%|          | 0.00/747M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata/MP16_Pro_filtered.csv to data/mp16/metadata/MP16_Pro_filtered.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d0553daac944c7969abc1b09437759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MP16_Pro_places365.csv:   0%|          | 0.00/859M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata/MP16_Pro_places365.csv to data/mp16/metadata/MP16_Pro_places365.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0ef486bef42f7a2d8ac753241027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mp16_urls.csv:   0%|          | 0.00/385M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata/mp16_urls.csv to data/mp16/metadata/mp16_urls.csv\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download, hf_hub_download, login\n",
    "\n",
    "login(token=\"\")\n",
    "\n",
    "path = snapshot_download(\n",
    "    repo_id=\"tduongvn/ACMMM25-Geolocation\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=[\"*.tar\"],\n",
    "    local_dir=\"data/mp16/\",\n",
    "    use_auth_token=True  # will use your local token from `huggingface-cli login`\n",
    ")\n",
    "print(f\"Downloaded dataset to {path}\")\n",
    "\n",
    "files = [\n",
    "    \"metadata/MP16_Pro_filtered.csv\",\n",
    "    \"metadata/MP16_Pro_places365.csv\",\n",
    "    \"metadata/mp16_urls.csv\"\n",
    "]\n",
    "for file in files:\n",
    "    path = hf_hub_download(\n",
    "        repo_id=\"Jia-py/MP16-Pro\",\n",
    "        filename=file,\n",
    "        repo_type=\"dataset\",\n",
    "        local_dir=\"data/mp16/\",\n",
    "        use_auth_token=True  # will use your local token from `huggingface-cli login`\n",
    "    )\n",
    "    print(f\"Downloaded {file} to {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5bdea04-15b3-4fba-bbf3-2bee63c588fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:02:54.328238Z",
     "iopub.status.busy": "2025-05-25T08:02:54.327934Z",
     "iopub.status.idle": "2025-05-25T08:02:54.456232Z",
     "shell.execute_reply": "2025-05-25T08:02:54.455174Z",
     "shell.execute_reply.started": "2025-05-25T08:02:54.328219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mv data/mp16/metadata/*.csv data/mp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eab080eb-9055-4d48-bf9f-f22e33e6d9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:02:54.457776Z",
     "iopub.status.busy": "2025-05-25T08:02:54.457456Z",
     "iopub.status.idle": "2025-05-25T08:02:55.981425Z",
     "shell.execute_reply": "2025-05-25T08:02:55.980631Z",
     "shell.execute_reply.started": "2025-05-25T08:02:54.457741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_mp16.tar  MP16_Pro_filtered.csv   mp16_urls.csv\n",
      "metadata\t   MP16_Pro_places365.csv\n"
     ]
    }
   ],
   "source": [
    "!ls data/mp16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf93114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:02:55.982776Z",
     "iopub.status.busy": "2025-05-25T08:02:55.982521Z",
     "iopub.status.idle": "2025-05-25T08:03:03.901230Z",
     "shell.execute_reply": "2025-05-25T08:03:03.900587Z",
     "shell.execute_reply.started": "2025-05-25T08:02:55.982752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/lctngdng/im2gps3k\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = ''\n",
    "os.environ['KAGGLE_KEY'] = ''\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "api.dataset_download_files('lctngdng/im2gps3k', path='data/im2gps3k', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fed67e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:03:03.902341Z",
     "iopub.status.busy": "2025-05-25T08:03:03.902089Z",
     "iopub.status.idle": "2025-05-25T08:03:04.047417Z",
     "shell.execute_reply": "2025-05-25T08:03:04.046833Z",
     "shell.execute_reply.started": "2025-05-25T08:03:03.902320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# Load Natural Earth country polygons\n",
    "shp_path = shpreader.natural_earth(\n",
    "    resolution='110m',\n",
    "    category='cultural',\n",
    "    name='admin_0_countries'\n",
    ")\n",
    "world = gpd.read_file(shp_path)[[\"ADMIN\", \"geometry\"]].to_crs(epsg=4326)\n",
    "# Build spatial index for performance\n",
    "sindex = world.sindex\n",
    "\n",
    "# Function returns country name for a given latitude/longitude\n",
    "def point_to_country(lat, lon, countries=world, index=sindex):\n",
    "    pt = Point(lon, lat)\n",
    "    # Find candidate polygons via spatial index\n",
    "    candidates = list(index.intersection(pt.bounds))\n",
    "    # Check strict land contains\n",
    "    for idx in candidates:\n",
    "        if countries.geometry.iloc[idx].contains(pt):\n",
    "            return countries.ADMIN.iloc[idx]\n",
    "    # Fallback to intersects for border/water cases\n",
    "    for idx in candidates:\n",
    "        if countries.geometry.iloc[idx].intersects(pt):\n",
    "            return countries.ADMIN.iloc[idx]\n",
    "    # No match found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027ca254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:03:04.048496Z",
     "iopub.status.busy": "2025-05-25T08:03:04.048263Z",
     "iopub.status.idle": "2025-05-25T08:03:05.339786Z",
     "shell.execute_reply": "2025-05-25T08:03:05.339029Z",
     "shell.execute_reply.started": "2025-05-25T08:03:04.048478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMG_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>S3_Label</th>\n",
       "      <th>S16_Label</th>\n",
       "      <th>S365_Label</th>\n",
       "      <th>Prob_indoor</th>\n",
       "      <th>Prob_natural</th>\n",
       "      <th>Prob_urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000269685_e60e9cdfb4_1125_78841376@N00.jpg</td>\n",
       "      <td>78841376@N00</td>\n",
       "      <td>32.325436</td>\n",
       "      <td>-64.764404</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>353</td>\n",
       "      <td>0.274242</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>0.680645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000304467_1a75a200b1_1296_78841376@N00.jpg</td>\n",
       "      <td>78841376@N00</td>\n",
       "      <td>32.325436</td>\n",
       "      <td>-64.764404</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>325</td>\n",
       "      <td>0.414407</td>\n",
       "      <td>0.220912</td>\n",
       "      <td>0.364681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001048550_8e4b47d165_1051_78841376@N00.jpg</td>\n",
       "      <td>78841376@N00</td>\n",
       "      <td>32.325436</td>\n",
       "      <td>-64.764404</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.969903</td>\n",
       "      <td>0.022771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005977048_5ccf8b05d3_1201_91728102@N00.jpg</td>\n",
       "      <td>91728102@N00</td>\n",
       "      <td>29.976052</td>\n",
       "      <td>122.390356</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>273</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.476665</td>\n",
       "      <td>0.519468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1008804117_ce4e6fef8a_1349_97522422@N00.jpg</td>\n",
       "      <td>97522422@N00</td>\n",
       "      <td>46.478536</td>\n",
       "      <td>30.758714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0.973878</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.023670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        IMG_ID        AUTHOR        LAT  \\\n",
       "0  1000269685_e60e9cdfb4_1125_78841376@N00.jpg  78841376@N00  32.325436   \n",
       "1  1000304467_1a75a200b1_1296_78841376@N00.jpg  78841376@N00  32.325436   \n",
       "2  1001048550_8e4b47d165_1051_78841376@N00.jpg  78841376@N00  32.325436   \n",
       "3  1005977048_5ccf8b05d3_1201_91728102@N00.jpg  91728102@N00  29.976052   \n",
       "4  1008804117_ce4e6fef8a_1349_97522422@N00.jpg  97522422@N00  46.478536   \n",
       "\n",
       "          LON  S3_Label  S16_Label  S365_Label  Prob_indoor  Prob_natural  \\\n",
       "0  -64.764404         2         12         353     0.274242      0.045113   \n",
       "1  -64.764404         0          4         325     0.414407      0.220912   \n",
       "2  -64.764404         1          8          36     0.007326      0.969903   \n",
       "3  122.390356         2          6         273     0.003868      0.476665   \n",
       "4   30.758714         0          0         198     0.973878      0.002453   \n",
       "\n",
       "   Prob_urban  \n",
       "0    0.680645  \n",
       "1    0.364681  \n",
       "2    0.022771  \n",
       "3    0.519468  \n",
       "4    0.023670  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/im2gps3k/im2gps3k_places365.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c7e87a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:03:05.341877Z",
     "iopub.status.busy": "2025-05-25T08:03:05.341146Z",
     "iopub.status.idle": "2025-05-25T08:03:07.155769Z",
     "shell.execute_reply": "2025-05-25T08:03:07.155210Z",
     "shell.execute_reply.started": "2025-05-25T08:03:05.341848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def is_target_country(row):\n",
    "    lat, lon = row[\"LAT\"], row[\"LON\"]\n",
    "    return point_to_country(lat, lon) in [\"Ukraine\", \"Israel\", \"Russia\", \"Palestine\"]\n",
    "\n",
    "# apply row‐wise and get a boolean mask\n",
    "mask = df.apply(is_target_country, axis=1)\n",
    "\n",
    "# filter the dataframe\n",
    "df_filtered = df[mask]\n",
    "df_filtered.head()\n",
    "df_filtered.to_csv(\"data/im2gps3k/im2gps3k_places365.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97e0609d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:03:07.156690Z",
     "iopub.status.busy": "2025-05-25T08:03:07.156466Z",
     "iopub.status.idle": "2025-05-25T08:03:07.174339Z",
     "shell.execute_reply": "2025-05-25T08:03:07.173855Z",
     "shell.execute_reply.started": "2025-05-25T08:03:07.156673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "Path(\"data/im2gps3k/filtered_im2gps3k\").mkdir(parents=True, exist_ok=True)\n",
    "for image in df_filtered[\"IMG_ID\"]:\n",
    "    shutil.copyfile(\n",
    "        f\"data/im2gps3k/im2gps3ktest/{image}\",\n",
    "        f\"data/im2gps3k/filtered_im2gps3k/{image}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07468dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import os\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils.utils import MP16Dataset\n",
    "from utils.G3 import G3\n",
    "from accelerate import Accelerator, DistributedDataParallelKwargs\n",
    "from zeroshot_prediction import ZeroShotPredictor\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TUNE_RESULTS_DIR = \"results/tune\"\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameter(trial: optuna.trial.Trial, positional_encoding_type, neural_network_type):\n",
    "\n",
    "    hparams_pe = {}\n",
    "    if positional_encoding_type == \"projectionrff\":\n",
    "        hparams_pe[\"projection\"] = trial.suggest_categorical(\"projection\", [\"ecef\", \"mercator\", \"eep\"])\n",
    "        hparams_pe[\"sigma\"] = [2**0, 2**4, 2**8]\n",
    "    elif positional_encoding_type == \"projection\":\n",
    "        hparams_pe[\"projection\"] = trial.suggest_categorical(\"projection\", [\"ecef\", \"mercator\", \"eep\"])\n",
    "    elif positional_encoding_type == \"sh\":\n",
    "        hparams_pe[\"legendre_polys\"] = trial.suggest_int(\"legendre_polys\", 10, 30, step=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported encoding type: {positional_encoding_type}\")\n",
    "\n",
    "    hparams_nn = {}\n",
    "    if neural_network_type == \"siren\":\n",
    "        hparams_nn[\"hidden_dim\"] = trial.suggest_int(\"hidden_dim\", 256, 1024, step=256)\n",
    "        hparams_nn[\"num_layers\"] = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    elif neural_network_type == \"mlp\":\n",
    "        hparams_nn[\"hidden_dim\"] = trial.suggest_int(\"hidden_dim\", 32, 128, step=32)\n",
    "    elif neural_network_type == \"rffmlp\":\n",
    "        hparams_nn[\"sigma\"] = [2**0, 2**4, 2**8]\n",
    "        hparams_nn[\"hidden_dim\"] = trial.suggest_int(\"hidden_dim\", 32, 128, step=32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported network type: {neural_network_type}\")\n",
    "\n",
    "    hparams_opt = {}\n",
    "    hparams_opt[\"lr\"] = trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True)\n",
    "    hparams_opt[\"wd\"] = trial.suggest_float(\"wd\", 5e-7, 5e-6, log=True)\n",
    "\n",
    "    hparams = {}\n",
    "    hparams.update(hparams_pe)\n",
    "    hparams.update(hparams_nn)\n",
    "    hparams[\"optimizer\"] = hparams_opt\n",
    "    \n",
    "    hparams['harmonics_calculation'] = \"analytic\"\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec258cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1epoch(train_loader, val_loader, earlystopper, model, vision_processor, text_processor, optimizer, scheduler, device, accelerator=None):\n",
    "    # === Training ===\n",
    "    model.train()\n",
    "    t = tqdm(train_loader, disable=not accelerator.is_local_main_process)\n",
    "    for i, (images, texts, longitude, latitude) in enumerate(t):\n",
    "        texts = text_processor(text=texts, padding='max_length', truncation=True, return_tensors='pt', max_length=77)\n",
    "        images = images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        longitude = longitude.to(device).float()\n",
    "        latitude = latitude.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images, texts, longitude, latitude, return_loss=True)\n",
    "        loss = output['loss']\n",
    "        \n",
    "        # Gradient step\n",
    "        if accelerator:\n",
    "            accelerator.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        if i % 1 == 0:\n",
    "            t.set_description(f\"Train | step {i}, loss {loss.item():.4f}, lr {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for images, texts, longitude, latitude in val_loader:\n",
    "            texts = text_processor(text=texts, padding='max_length', truncation=True, return_tensors='pt', max_length=77)\n",
    "            images = images.to(device)\n",
    "            texts = texts.to(device)\n",
    "            longitude = longitude.to(device).float()\n",
    "            latitude = latitude.to(device).float()\n",
    "\n",
    "            output = model(images, texts, longitude, latitude, return_loss=True)\n",
    "            val_losses.append(output['loss'].item())\n",
    "\n",
    "    val_loss_avg = sum(val_losses) / len(val_losses)\n",
    "    print(f\"Validation Loss: {val_loss_avg:.4f}\")\n",
    "    return val_loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b8dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T08:26:48.552964Z",
     "iopub.status.busy": "2025-05-25T08:26:48.552619Z",
     "iopub.status.idle": "2025-05-25T08:26:48.581441Z",
     "shell.execute_reply": "2025-05-25T08:26:48.580594Z",
     "shell.execute_reply.started": "2025-05-25T08:26:48.552942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tune(positional_encoding_type, neural_network_type, dataset_name=\"mp16\"):\n",
    "    n_trials = 5\n",
    "    timeout = 90 * 60 # seconds\n",
    "    epochs = 5\n",
    "\n",
    "    def objective(trial: optuna.trial.Trial) -> float:\n",
    "        hparams = get_hyperparameter(trial, positional_encoding_type, neural_network_type)\n",
    "\n",
    "        ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "        accelerator = Accelerator(kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "        device = accelerator.device\n",
    "        model = G3(\n",
    "            device, \n",
    "            positional_encoding_type,\n",
    "            neural_network_type,\n",
    "            hparams=hparams,\n",
    "        ).to(device)\n",
    "\n",
    "        # Initialize dataset\n",
    "        dataset = MP16Dataset(\n",
    "            vision_processor=model.vision_processor,\n",
    "            text_processor=model.text_processor,\n",
    "            root_path='data/mp16/',\n",
    "            image_data_path='filtered_mp16.tar'\n",
    "        )\n",
    "\n",
    "        # Split dataset\n",
    "        train_size = int(0.9 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(\n",
    "            dataset, [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=16, pin_memory=True, prefetch_factor=5)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=16, pin_memory=True, prefetch_factor=5)\n",
    "\n",
    "\n",
    "\n",
    "        params = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.size())\n",
    "                params.append(param)\n",
    "\n",
    "        optimizer = torch.optim.AdamW([param for name,param in model.named_parameters() if param.requires_grad], lr=hparams['optimizer']['lr'], weight_decay=hparams['optimizer']['wd'])\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.87)\n",
    "\n",
    "        model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(\n",
    "            model, optimizer, train_loader, val_loader, scheduler\n",
    "        )\n",
    "\n",
    "        earlystopper = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            val_loss = train_1epoch(train_loader, val_loader, earlystopper, model, model.vision_processor, model.text_processor, optimizer, scheduler, device, accelerator)\n",
    "\n",
    "            trial.report(val_loss, step=epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    pruner = optuna.pruners.MedianPruner()\n",
    "    study_name = f\"{dataset_name}-{positional_encoding_type}-{neural_network_type}\"\n",
    "    os.makedirs(f\"{TUNE_RESULTS_DIR}/{dataset_name}/runs/\", exist_ok=True)\n",
    "    storage_name = f\"sqlite:///{TUNE_RESULTS_DIR}/{dataset_name}/runs/{study_name}.db\"\n",
    "    study = optuna.create_study(study_name=study_name, direction=\"minimize\", \n",
    "                                storage=storage_name, load_if_exists=True, \n",
    "                                pruner=pruner)\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    study.trials_dataframe()\n",
    "\n",
    "    runsummary = f\"{TUNE_RESULTS_DIR}/{dataset_name}/runs/{positional_encoding_type}-{neural_network_type}.csv\"\n",
    "    os.makedirs(os.path.dirname(runsummary), exist_ok=True)\n",
    "\n",
    "    study.trials_dataframe().to_csv(runsummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_summaries(dataset=\"mp16\"):\n",
    "    tune_results_dir_this_datset = os.path.join(TUNE_RESULTS_DIR, dataset)\n",
    "    runsdir = os.path.join(TUNE_RESULTS_DIR, f\"{dataset}/runs\")\n",
    "\n",
    "    csvs = [csv for csv in os.listdir(runsdir) if csv.endswith(\"csv\") and csv != \"summary.csv\"]\n",
    "\n",
    "    summary = []\n",
    "    hparams = {}\n",
    "    for csv in csvs:\n",
    "        df = pd.read_csv(os.path.join(runsdir, csv))\n",
    "        best_run = df.sort_values(by=\"value\").iloc[0]\n",
    "        value = best_run.value\n",
    "        params = {k.replace(\"params_\", \"\"): v for k, v in best_run.to_dict().items() if \"params\" in k}\n",
    "        pe, nn = csv.replace(\".csv\", \"\").split(\"-\")\n",
    "        hparams[f\"{pe}-{nn}\"] = params\n",
    "\n",
    "        sum = {\n",
    "            \"pe\":pe,\n",
    "            \"nn\":nn,\n",
    "            \"value\":value\n",
    "        }\n",
    "        sum.update(params)\n",
    "\n",
    "        summary.append(sum)\n",
    "\n",
    "    summary = pd.DataFrame(summary).sort_values(\"value\").set_index([\"pe\",\"nn\"])\n",
    "    summary.to_csv(os.path.join(tune_results_dir_this_datset, \"summary.csv\"))\n",
    "\n",
    "    print(\"writing \" + os.path.join(tune_results_dir_this_datset, \"hparams.yaml\"))\n",
    "    with open(os.path.join(tune_results_dir_this_datset, \"hparams.yaml\"), 'w') as f:\n",
    "        yaml.dump(hparams, f)\n",
    "\n",
    "    value_matrix = pd.pivot_table(summary.value.reset_index(), index=\"pe\", columns=\"nn\", values=[\"value\"])[\"value\"]\n",
    "    print(\"writing \" + os.path.join(tune_results_dir_this_datset, \"values.csv\"))\n",
    "    value_matrix.to_csv(os.path.join(tune_results_dir_this_datset, \"values.csv\"))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(value_matrix)\n",
    "    ax.set_xticks(range(len(value_matrix.columns)))\n",
    "    ax.set_xticklabels(value_matrix.columns)\n",
    "    ax.set_xlabel(value_matrix.columns.name)\n",
    "\n",
    "    ax.set_yticks(range(len(value_matrix.index)))\n",
    "    ax.set_yticklabels(value_matrix.index)\n",
    "    ax.set_ylabel(value_matrix.index.name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    print(\"writing \"+os.path.join(tune_results_dir_this_datset, \"values.png\"))\n",
    "    fig.savefig(os.path.join(tune_results_dir_this_datset, \"values.png\"), transparent=True, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f640-56ac-4816-9c7e-f9c861f50e27",
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-25T08:31:14.742Z",
     "iopub.execute_input": "2025-05-25T08:27:34.815280Z",
     "iopub.status.busy": "2025-05-25T08:27:34.814624Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-25 08:27:36,358] A new study created in RDB with name: mp16-sh-siren\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ee3fe7567e43a1b3fe99c430081dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738d7475cdc44cd89338fd186329535f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525d7c45c18640dfaad4c4339ae5476e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268bfecd3661450bb0800480fb0de103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7ca45cb96c4dbea40adc700bbfed2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71cc2afe6b4430e8a6582a12321e468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c20c8fb75a475f9190dfc3f9a45653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d874105d61944f0a7c8679ec4ab0d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read text data success\n",
      "no exist tar index success, need building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42764it [00:01, 29798.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar index buidling success\n",
      "data columns:  42764\n",
      "location from str to float success\n",
      "logit_scale1 torch.Size([])\n",
      "logit_scale2 torch.Size([])\n",
      "logit_scale3 torch.Size([])\n",
      "location_encoder.neural_network.0.layers.0.weight torch.Size([768, 900])\n",
      "location_encoder.neural_network.0.layers.0.bias torch.Size([768])\n",
      "location_encoder.neural_network.0.layers.1.weight torch.Size([768, 768])\n",
      "location_encoder.neural_network.0.layers.1.bias torch.Size([768])\n",
      "location_encoder.neural_network.0.last_layer.weight torch.Size([512, 768])\n",
      "location_encoder.neural_network.0.last_layer.bias torch.Size([512])\n",
      "vision_projection_else_1.0.weight torch.Size([768, 768])\n",
      "vision_projection_else_1.0.bias torch.Size([768])\n",
      "vision_projection_else_1.2.weight torch.Size([768, 768])\n",
      "vision_projection_else_1.2.bias torch.Size([768])\n",
      "text_projection_else.0.weight torch.Size([768, 768])\n",
      "text_projection_else.0.bias torch.Size([768])\n",
      "text_projection_else.2.weight torch.Size([768, 768])\n",
      "text_projection_else.2.bias torch.Size([768])\n",
      "vision_projection_else_2.0.weight torch.Size([768, 768])\n",
      "vision_projection_else_2.0.bias torch.Size([768])\n",
      "vision_projection_else_2.2.weight torch.Size([768, 768])\n",
      "vision_projection_else_2.2.bias torch.Size([768])\n",
      "location_projection_else.0.weight torch.Size([512, 512])\n",
      "location_projection_else.0.bias torch.Size([512])\n",
      "location_projection_else.2.weight torch.Size([768, 512])\n",
      "location_projection_else.2.bias torch.Size([768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 7, loss 11.326229095458984, lr 3e-05:   5%|▍         | 8/168 [02:48<27:25, 10.28s/it]   "
     ]
    }
   ],
   "source": [
    "positional_encoders = [\"sh\"]\n",
    "neural_networks = [\"siren\"]\n",
    "for pe in positional_encoders:\n",
    "    for nn in neural_networks:\n",
    "        tune(pe, nn)\n",
    "\n",
    "compile_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57046b7a-fe0b-4571-8f45-0bc9255497f1",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
