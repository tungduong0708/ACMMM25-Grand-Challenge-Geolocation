{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac28e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import yaml\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import required utilities\n",
    "from utils.G3 import G3\n",
    "from utils.utils import search_with_image_and_text, extract_image_search_candidates\n",
    "from utils.prompt import combine_prompts\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class BatchKeyframePredictor:\n",
    "    \"\"\"\n",
    "    Batch prediction class for directory of keyframes/images.\n",
    "    \n",
    "    This class:\n",
    "    1. Takes a directory of keyframes/images as input\n",
    "    2. For each image, performs image search and collects the first N result links\n",
    "    3. Adds all links to a global dictionary (no duplicates)\n",
    "    4. Processes the links in batches\n",
    "    5. For each batch, runs LLM prediction using all images and calculates similarity scores\n",
    "    6. Selects the GPS with the highest average similarity across all images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_path: str, device: str = \"cuda\", index_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the BatchKeyframePredictor.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path (str): Path to G3 model checkpoint\n",
    "            device (str): Device to run model on (\"cuda\" or \"cpu\")\n",
    "            index_path (str): Path to FAISS index for RAG (required)\n",
    "        \"\"\"\n",
    "        if index_path is None:\n",
    "            raise ValueError(\"index_path is required for batch prediction. FAISS index is mandatory for RAG.\")\n",
    "        \n",
    "        if not os.path.exists(index_path):\n",
    "            raise FileNotFoundError(f\"FAISS index file not found: {index_path}\")\n",
    "        self.device = torch.device(device)\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        \n",
    "        # Initialize G3 model\n",
    "        base_path = Path(r\"C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\example.ipynb\").parent\n",
    "        hparams = yaml.safe_load(open(base_path / \"hparams.yaml\", \"r\"))\n",
    "        pe = \"projection_mercator\"\n",
    "        nn = \"rffmlp\"\n",
    "        \n",
    "        self.model = G3(\n",
    "            device=device,\n",
    "            positional_encoding_type=pe,\n",
    "            neural_network_type=nn,\n",
    "            hparams=hparams[f\"{pe}_{nn}\"],\n",
    "        )\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        self.model.to(device)\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load FAISS index for RAG (required)\n",
    "        import faiss\n",
    "        try:\n",
    "            self.index = faiss.read_index(index_path)\n",
    "            print(f\"âœ… Successfully loaded FAISS index from: {index_path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load FAISS index from {index_path}: {e}\")\n",
    "        \n",
    "        # Get API key\n",
    "        self.api_key = os.getenv(\"API_KEY\")\n",
    "        if self.api_key is None:\n",
    "            raise ValueError(\"API_KEY environment variable is not set.\")\n",
    "        \n",
    "        # Supported image extensions\n",
    "        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}\n",
    "        \n",
    "        # Search candidates dictionary: {link: full_candidate_string}\n",
    "        self.candidates_dict: Dict[str, str] = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_and_parse_json(raw_text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Extract JSON content between first { and last } and parse it.\n",
    "        \n",
    "        Args:\n",
    "            raw_text (str): Raw response text from LLM\n",
    "            \n",
    "        Returns:\n",
    "            dict: Parsed JSON data\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If no valid JSON found or parsing fails\n",
    "        \"\"\"\n",
    "        # Find first { and last }\n",
    "        first_brace = raw_text.find('{')\n",
    "        last_brace = raw_text.rfind('}')\n",
    "        \n",
    "        if first_brace == -1 or last_brace == -1 or first_brace >= last_brace:\n",
    "            raise ValueError(f\"No valid JSON braces found in response: {raw_text}\")\n",
    "        \n",
    "        # Extract JSON substring\n",
    "        json_str = raw_text[first_brace:last_brace + 1]\n",
    "        \n",
    "        try:\n",
    "            # Parse JSON\n",
    "            parsed_data = json.loads(json_str)\n",
    "            return parsed_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {json_str}, Error: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid_enhanced_gps_dict(gps_data):\n",
    "        \"\"\"\n",
    "        Check if GPS data dict has valid enhanced format with latitude, longitude, location, and reason.\n",
    "        \"\"\"\n",
    "        if not isinstance(gps_data, dict):\n",
    "            return False\n",
    "            \n",
    "        required_fields = [\"latitude\", \"longitude\", \"location\", \"reason\"]\n",
    "        if not all(field in gps_data for field in required_fields):\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            lat = float(gps_data[\"latitude\"])\n",
    "            lon = float(gps_data[\"longitude\"])\n",
    "            \n",
    "            # Basic GPS coordinate validation\n",
    "            if -90 <= lat <= 90 and -180 <= lon <= 180:\n",
    "                return True\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "            \n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def image_to_base64(image_path: str) -> str:\n",
    "        \"\"\"Convert image file to base64 string.\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        return encoded_string\n",
    "\n",
    "    def get_llm_prediction_with_batch(\n",
    "        self,\n",
    "        base64_images: List[str],\n",
    "        batch_links: List[str],\n",
    "        candidates_gps: Optional[list] = None,\n",
    "        reverse_gps: Optional[list] = None,\n",
    "        image_paths: Optional[List[str]] = None,\n",
    "        transcript_file_path: str = \"\",\n",
    "        metadata_file_path: str = \"\",\n",
    "        n_coords: int = 15,\n",
    "        model_name: str = \"gemini-2.5-flash\"\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Get LLM prediction using multiple images and comprehensive context.\n",
    "        \n",
    "        Args:\n",
    "            base64_images: List of base64 encoded images\n",
    "            batch_links: List of links for this batch\n",
    "            candidates_gps: List of candidate GPS coordinates from RAG\n",
    "            reverse_gps: List of reverse GPS coordinates from RAG\n",
    "            image_paths: List of image file paths for metadata\n",
    "            transcript_file_path: Path to transcript file\n",
    "            metadata_file_path: Path to metadata JSON file\n",
    "            n_coords: Number of coordinates to include\n",
    "            model_name: Model to use for prediction\n",
    "            \n",
    "        Returns:\n",
    "            dict: Parsed prediction with latitude, longitude, location, reason\n",
    "        \"\"\"\n",
    "        # Get full candidates from the dictionary using the links\n",
    "        search_candidates = [self.candidates_dict[link] for link in batch_links if link in self.candidates_dict]\n",
    "        \n",
    "        # Create comprehensive prompt using all available context\n",
    "        combined_prompt = combine_prompts(\n",
    "            image_path=image_paths[0] if image_paths else \"\",  # Use first image path for reference\n",
    "            transcript_file_path=transcript_file_path,\n",
    "            metadata_file_path=metadata_file_path,\n",
    "            candidates_gps=candidates_gps[:n_coords] if candidates_gps else [],\n",
    "            reverse_gps=reverse_gps[:n_coords] if reverse_gps else [],\n",
    "            search_candidates=search_candidates,\n",
    "            n_search=len(search_candidates),\n",
    "            n_coords=n_coords,\n",
    "        )\n",
    "        \n",
    "        client = genai.Client(\n",
    "            api_key=self.api_key,\n",
    "            http_options=types.HttpOptions(timeout=1)\n",
    "        )\n",
    "        \n",
    "        # Convert base64 images to Parts\n",
    "        image_parts = []\n",
    "        for b64_img in base64_images:\n",
    "            image = types.Part.from_bytes(\n",
    "                data=base64.b64decode(b64_img), \n",
    "                mime_type=\"image/jpeg\"\n",
    "            )\n",
    "            image_parts.append(image)\n",
    "        \n",
    "        # Combine images with prompt\n",
    "        contents = image_parts + [combined_prompt]\n",
    "        \n",
    "        tools = [\n",
    "            types.Tool(google_search=types.GoogleSearch()),\n",
    "            types.Tool(url_context=types.UrlContext())\n",
    "        ]\n",
    "\n",
    "        config = types.GenerateContentConfig(\n",
    "            tools=tools,\n",
    "            response_modalities=[\"TEXT\"]\n",
    "        )\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=model_name,\n",
    "            contents=contents,\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        raw_text = response.text.strip() if response.text is not None else \"\"\n",
    "        \n",
    "        # Extract and parse JSON from response\n",
    "        parsed_json = self.extract_and_parse_json(raw_text)\n",
    "        return parsed_json\n",
    "\n",
    "    def calculate_similarity_scores(\n",
    "        self,\n",
    "        rgb_images: List[Image.Image], \n",
    "        predicted_coords: List[Tuple[float, float]]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate similarity scores between images and predicted coordinates.\n",
    "        \n",
    "        Args:\n",
    "            rgb_images: List of PIL Images\n",
    "            predicted_coords: List of (lat, lon) tuples\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Average similarity scores across all images for each coordinate\n",
    "        \"\"\"\n",
    "        all_similarities = []\n",
    "        \n",
    "        for rgb_image in rgb_images:\n",
    "            # Process image\n",
    "            image = self.model.vision_processor(images=rgb_image, return_tensors=\"pt\")[\n",
    "                \"pixel_values\"\n",
    "            ].reshape(-1, 224, 224)\n",
    "            image = image.unsqueeze(0).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                vision_output = self.model.vision_model(image)[1]\n",
    "\n",
    "                image_embeds = self.model.vision_projection_else_2(\n",
    "                    self.model.vision_projection(vision_output)\n",
    "                )\n",
    "                image_embeds = image_embeds / image_embeds.norm(\n",
    "                    p=2, dim=-1, keepdim=True\n",
    "                )  # b, 768\n",
    "\n",
    "                # Process coordinates\n",
    "                gps_batch = torch.tensor(predicted_coords, dtype=torch.float32).to(self.device)\n",
    "                gps_input = gps_batch.clone().detach().unsqueeze(0)  # Add batch dimension\n",
    "                b, c, _ = gps_input.shape\n",
    "                gps_input = gps_input.reshape(b * c, 2)\n",
    "                location_embeds = self.model.location_encoder(gps_input)\n",
    "                location_embeds = self.model.location_projection_else(\n",
    "                    location_embeds.reshape(b * c, -1)\n",
    "                )\n",
    "                location_embeds = location_embeds / location_embeds.norm(\n",
    "                    p=2, dim=-1, keepdim=True\n",
    "                )\n",
    "                location_embeds = location_embeds.reshape(b, c, -1)  # b, c, 768\n",
    "\n",
    "                similarity = torch.matmul(\n",
    "                    image_embeds.unsqueeze(1), location_embeds.permute(0, 2, 1)\n",
    "                )  # b, 1, c\n",
    "                similarity = similarity.squeeze(1).cpu().detach().numpy()\n",
    "                all_similarities.append(similarity[0])  # Remove batch dimension\n",
    "        \n",
    "        # Calculate average similarity across all images\n",
    "        avg_similarities = np.mean(all_similarities, axis=0)\n",
    "        return avg_similarities\n",
    "\n",
    "    def search_index(self, rgb_image, top_k=20):\n",
    "        \"\"\"\n",
    "        Search FAISS index for similar and dissimilar coordinates using image embeddings.\n",
    "        \n",
    "        Args:\n",
    "            rgb_image: PIL RGB Image\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (D, I, D_reverse, I_reverse) - distances and indices for positive and negative embeddings\n",
    "        \"\"\"\n",
    "        print(\"Searching FAISS index...\")\n",
    "        image = self.model.vision_processor(images=rgb_image, return_tensors=\"pt\")[\n",
    "            \"pixel_values\"\n",
    "        ].reshape(-1, 224, 224)\n",
    "        image = image.unsqueeze(0).to(self.device)  # Add batch dimension\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            vision_output = self.model.vision_model(image)[1]\n",
    "            image_embeds = self.model.vision_projection(vision_output)\n",
    "            image_embeds = image_embeds / image_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "            image_text_embeds = self.model.vision_projection_else_1(\n",
    "                self.model.vision_projection(vision_output)\n",
    "            )\n",
    "            image_text_embeds = image_text_embeds / image_text_embeds.norm(\n",
    "                p=2, dim=-1, keepdim=True\n",
    "            )\n",
    "\n",
    "            image_location_embeds = self.model.vision_projection_else_2(\n",
    "                self.model.vision_projection(vision_output)\n",
    "            )\n",
    "            image_location_embeds = image_location_embeds / image_location_embeds.norm(\n",
    "                p=2, dim=-1, keepdim=True\n",
    "            )\n",
    "\n",
    "            positive_image_embeds = torch.cat(\n",
    "                [image_embeds, image_text_embeds, image_location_embeds], dim=1\n",
    "            )\n",
    "            positive_image_embeds = (\n",
    "                positive_image_embeds.cpu().detach().numpy().astype(np.float32)\n",
    "            )\n",
    "\n",
    "            negative_image_embeds = positive_image_embeds * (-1.0)\n",
    "\n",
    "        # Search FAISS index (index is guaranteed to exist)\n",
    "        D, I = self.index.search(positive_image_embeds, top_k)\n",
    "        D_reverse, I_reverse = self.index.search(negative_image_embeds, top_k)\n",
    "        return D, I, D_reverse, I_reverse\n",
    "\n",
    "    def _get_gps_coordinates(self, I, I_reverse, database_csv_path):\n",
    "        \"\"\"\n",
    "        Helper method to get GPS coordinates from database using FAISS indices.\n",
    "        \n",
    "        Args:\n",
    "            I: FAISS indices for positive embeddings\n",
    "            I_reverse: FAISS indices for negative embeddings  \n",
    "            database_csv_path (str): Path to GPS coordinates database CSV\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (candidates_gps, reverse_gps) - lists of (lat, lon) tuples\n",
    "        \"\"\"\n",
    "        if I is None or I_reverse is None:\n",
    "            return [], []\n",
    "            \n",
    "        candidate_indices = I[0]\n",
    "        reverse_indices = I_reverse[0]\n",
    "        \n",
    "        candidates_gps = []\n",
    "        reverse_gps = []\n",
    "        \n",
    "        try:\n",
    "            import pandas as pd\n",
    "            for chunk in pd.read_csv(database_csv_path, chunksize=10000, usecols=[\"LAT\", \"LON\"]):\n",
    "                for idx in candidate_indices:\n",
    "                    if idx in chunk.index:\n",
    "                        lat = float(chunk.loc[idx, \"LAT\"])\n",
    "                        lon = float(chunk.loc[idx, \"LON\"])\n",
    "                        candidates_gps.append((lat, lon))\n",
    "\n",
    "                for ridx in reverse_indices:\n",
    "                    if ridx in chunk.index:\n",
    "                        lat = float(chunk.loc[ridx, \"LAT\"])\n",
    "                        lon = float(chunk.loc[ridx, \"LON\"])\n",
    "                        reverse_gps.append((lat, lon))\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error loading GPS coordinates from database: {e}\")\n",
    "            \n",
    "        return candidates_gps, reverse_gps\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        keyframes_dir: str,\n",
    "        database_csv_path: str = \"\",\n",
    "        serpapi_key: str = \"\",\n",
    "        imgbb_key: str = \"\",\n",
    "        transcript_file_path: str = \"\",\n",
    "        metadata_file_path: str = \"\",\n",
    "        batch_size: int = 10,\n",
    "        links_per_image: int = 3,\n",
    "        top_k: int = 20,\n",
    "        model_name: str = \"gemini-2.5-flash\"\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Comprehensive batch prediction for directory of keyframes/images.\n",
    "        \n",
    "        Args:\n",
    "            keyframes_dir (str): Directory containing keyframe/image files\n",
    "            database_csv_path (str): Path to GPS coordinates database CSV for RAG (required)\n",
    "            serpapi_key (str): SerpAPI key for image search\n",
    "            imgbb_key (str): imgbb API key for image upload\n",
    "            transcript_file_path (str): Path to transcript file\n",
    "            metadata_file_path (str): Path to metadata JSON file\n",
    "            batch_size (int): Number of links to process in each batch (default: 10)\n",
    "            links_per_image (int): Number of search result links to extract per image (default: 3)\n",
    "            top_k (int): Number of top FAISS results for RAG (default: 20)\n",
    "            model_name (str): LLM model name to use\n",
    "            \n",
    "        Returns:\n",
    "            dict: Best prediction with latitude, longitude, location, reason, and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        # Validate required parameters for RAG\n",
    "        if not database_csv_path:\n",
    "            raise ValueError(\"database_csv_path is required for RAG coordinates. This parameter is mandatory.\")\n",
    "        \n",
    "        if not os.path.exists(database_csv_path):\n",
    "            raise FileNotFoundError(f\"Database CSV file not found: {database_csv_path}\")\n",
    "        \n",
    "        # Reset candidates dictionary for new prediction\n",
    "        self.candidates_dict = {}\n",
    "        \n",
    "        # Step 1: Collect all image files\n",
    "        keyframes_path = Path(keyframes_dir)\n",
    "        if not keyframes_path.exists():\n",
    "            raise ValueError(f\"Directory does not exist: {keyframes_dir}\")\n",
    "        \n",
    "        image_files = []\n",
    "        for file_path in keyframes_path.iterdir():\n",
    "            if file_path.is_file() and file_path.suffix.lower() in self.image_extensions:\n",
    "                image_files.append(file_path)\n",
    "        \n",
    "        if not image_files:\n",
    "            raise ValueError(f\"No image files found in directory: {keyframes_dir}\")\n",
    "        \n",
    "        print(f\"ğŸ“ Found {len(image_files)} image files in {keyframes_dir}\")\n",
    "        \n",
    "        # Step 2: For each image, perform search and collect links + RAG coordinates\n",
    "        base64_images = []\n",
    "        rgb_images = []\n",
    "        image_paths = []\n",
    "        all_candidates_gps = []\n",
    "        all_reverse_gps = []\n",
    "        \n",
    "        for i, image_file in enumerate(image_files):\n",
    "            print(f\"ğŸ–¼ï¸ Processing image {i+1}/{len(image_files)}: {image_file.name}\")\n",
    "            \n",
    "            try:\n",
    "                # Convert to base64 for later use\n",
    "                base64_img = self.image_to_base64(str(image_file))\n",
    "                base64_images.append(base64_img)\n",
    "                \n",
    "                # Load RGB image for similarity calculation and FAISS search\n",
    "                rgb_img = Image.open(image_file).convert(\"RGB\")\n",
    "                rgb_images.append(rgb_img)\n",
    "                image_paths.append(str(image_file))\n",
    "                \n",
    "                # Perform FAISS search for RAG coordinates\n",
    "                if self.index is not None and database_csv_path:\n",
    "                    print(f\"ğŸ” Searching FAISS index for RAG coordinates...\")\n",
    "                    D, I, D_reverse, I_reverse = self.search_index(rgb_img, top_k)\n",
    "                    candidates_gps, reverse_gps = self._get_gps_coordinates(I, I_reverse, database_csv_path)\n",
    "                    all_candidates_gps.extend(candidates_gps)\n",
    "                    all_reverse_gps.extend(reverse_gps)\n",
    "                    print(f\"ï¿½ Found {len(candidates_gps)} candidate GPS and {len(reverse_gps)} reverse GPS coordinates\")\n",
    "                \n",
    "                # Perform image search for web candidates\n",
    "                print(f\"ï¿½ğŸ” Searching web for image: {image_file.name}\")\n",
    "                search_results = search_with_image_and_text(\n",
    "                    image_path=str(image_file),\n",
    "                    search_text=\"\",  # Image-only search\n",
    "                    serpapi_key=serpapi_key,\n",
    "                    imgbb_key=imgbb_key\n",
    "                )\n",
    "                \n",
    "                # Extract candidate links\n",
    "                search_candidates = extract_image_search_candidates(\n",
    "                    search_results, \n",
    "                    no_results=links_per_image\n",
    "                )\n",
    "                \n",
    "                # Store candidates in dictionary: {link: full_candidate_string}\n",
    "                for candidate in search_candidates:\n",
    "                    print(f\"ğŸ”— Found candidate: {candidate}\")\n",
    "                    if candidate.startswith(\"Link: \") and \" | Title: \" in candidate:\n",
    "                        link = candidate.split(\" | Title: \")[0].replace(\"Link: \", \"\")\n",
    "                        if link != \"No link\" and link.startswith(\"http\"):\n",
    "                            self.candidates_dict[link] = candidate\n",
    "                \n",
    "                print(f\"âœ… Found {len(search_candidates)} web candidates for {image_file.name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error processing {image_file.name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Remove duplicates from RAG coordinates\n",
    "        all_candidates_gps = list(set(all_candidates_gps))\n",
    "        all_reverse_gps = list(set(all_reverse_gps))\n",
    "        \n",
    "        print(f\"ğŸ”— Total unique web links collected: {len(self.candidates_dict)}\")\n",
    "        print(f\"ğŸ“ Total unique RAG candidates GPS: {len(all_candidates_gps)}\")\n",
    "        print(f\"ğŸ“ Total unique RAG reverse GPS: {len(all_reverse_gps)}\")\n",
    "        \n",
    "        if not self.candidates_dict and not all_candidates_gps:\n",
    "            raise ValueError(\"No valid search result links or RAG coordinates found from any images\")\n",
    "        \n",
    "        # Step 3: Process links in batches and run LLM predictions with comprehensive context\n",
    "        links_list = list(self.candidates_dict.keys())\n",
    "        all_predictions = {}  # {(lat, lon): prediction_dict}\n",
    "        \n",
    "        # If we have web links, process them in batches\n",
    "        if links_list:\n",
    "            for batch_start in range(0, len(links_list), batch_size):\n",
    "                batch_end = min(batch_start + batch_size, len(links_list))\n",
    "                batch_links = links_list[batch_start:batch_end]\n",
    "                \n",
    "                print(f\"ğŸ”¥ Processing batch {batch_start//batch_size + 1}: {len(batch_links)} links\")\n",
    "                \n",
    "                # Try to get prediction for this batch\n",
    "                max_retries = 3\n",
    "                for retry in range(max_retries):\n",
    "                    try:\n",
    "                        prediction = self.get_llm_prediction_with_batch(\n",
    "                            base64_images=base64_images,\n",
    "                            batch_links=batch_links,\n",
    "                            candidates_gps=all_candidates_gps,\n",
    "                            reverse_gps=all_reverse_gps,\n",
    "                            image_paths=image_paths,\n",
    "                            transcript_file_path=transcript_file_path,\n",
    "                            metadata_file_path=metadata_file_path,\n",
    "                            n_coords=15,\n",
    "                            model_name=model_name\n",
    "                        )\n",
    "                        print(prediction)\n",
    "                        \n",
    "                        if self.is_valid_enhanced_gps_dict(prediction):\n",
    "                            coords = (prediction[\"latitude\"], prediction[\"longitude\"])\n",
    "                            all_predictions[coords] = prediction\n",
    "                            print(f\"âœ… Batch prediction successful: {coords}\")\n",
    "                            break\n",
    "                        else:\n",
    "                            print(f\"âš ï¸ Invalid prediction format in batch, retrying... ({retry+1}/{max_retries})\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Batch prediction failed ({retry+1}/{max_retries}): {e}\")\n",
    "                        if retry == max_retries - 1:\n",
    "                            print(f\"âš ï¸ Skipping batch after {max_retries} failures\")\n",
    "        \n",
    "        # If we only have RAG coordinates (no web links), make prediction with RAG only\n",
    "        elif all_candidates_gps:\n",
    "            print(\"ğŸ”¥ No web links found, using RAG coordinates only...\")\n",
    "            max_retries = 3\n",
    "            for retry in range(max_retries):\n",
    "                try:\n",
    "                    prediction = self.get_llm_prediction_with_batch(\n",
    "                        base64_images=base64_images,\n",
    "                        batch_links=[],  # No web links\n",
    "                        candidates_gps=all_candidates_gps,\n",
    "                        reverse_gps=all_reverse_gps,\n",
    "                        image_paths=image_paths,\n",
    "                        transcript_file_path=transcript_file_path,\n",
    "                        metadata_file_path=metadata_file_path,\n",
    "                        n_coords=15,\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    \n",
    "                    if self.is_valid_enhanced_gps_dict(prediction):\n",
    "                        coords = (prediction[\"latitude\"], prediction[\"longitude\"])\n",
    "                        all_predictions[coords] = prediction\n",
    "                        print(f\"âœ… RAG-only prediction successful: {coords}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ Invalid RAG prediction format, retrying... ({retry+1}/{max_retries})\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ RAG prediction failed ({retry+1}/{max_retries}): {e}\")\n",
    "                    if retry == max_retries - 1:\n",
    "                        print(f\"âš ï¸ RAG prediction failed after {max_retries} attempts\")\n",
    "        \n",
    "        if not all_predictions:\n",
    "            raise ValueError(\"No valid predictions obtained from any batch\")\n",
    "        \n",
    "        # Step 4: Calculate similarity scores and select best prediction\n",
    "        predicted_coords = list(all_predictions.keys())\n",
    "        print(f\"ğŸ¯ Calculating similarity scores for {len(predicted_coords)} predictions...\")\n",
    "        \n",
    "        avg_similarities = self.calculate_similarity_scores(\n",
    "            rgb_images=rgb_images,\n",
    "            predicted_coords=predicted_coords\n",
    "        )\n",
    "        \n",
    "        # Find best prediction\n",
    "        best_idx = np.argmax(avg_similarities)\n",
    "        best_coords = predicted_coords[best_idx]\n",
    "        best_prediction = all_predictions[best_coords]\n",
    "        \n",
    "        # Add metadata to result\n",
    "        result = best_prediction.copy()\n",
    "        result[\"metadata\"] = {\n",
    "            \"num_images_processed\": len(image_files),\n",
    "            \"num_unique_links\": len(self.candidates_dict),\n",
    "            \"num_rag_candidates\": len(all_candidates_gps),\n",
    "            \"num_rag_reverse\": len(all_reverse_gps),\n",
    "            \"num_predictions\": len(all_predictions),\n",
    "            \"similarity_scores\": avg_similarities.tolist(),\n",
    "            \"all_predictions\": {str(coords): pred for coords, pred in all_predictions.items()},\n",
    "            \"best_similarity_score\": float(avg_similarities[best_idx]),\n",
    "            \"batch_size\": batch_size,\n",
    "            \"links_per_image\": links_per_image,\n",
    "            \"top_k_faiss\": top_k,\n",
    "            \"database_csv_path\": database_csv_path,\n",
    "            \"transcript_file_path\": transcript_file_path,\n",
    "            \"metadata_file_path\": metadata_file_path,\n",
    "            \"candidates_dict\": self.candidates_dict,\n",
    "            \"rag_coordinates\": {\n",
    "                \"candidates_gps\": all_candidates_gps,\n",
    "                \"reverse_gps\": all_reverse_gps\n",
    "            },\n",
    "            \"has_faiss_index\": self.index is not None,\n",
    "            \"processing_mode\": \"comprehensive\" if self.candidates_dict and all_candidates_gps else \n",
    "                             \"web_only\" if self.candidates_dict else \"rag_only\"\n",
    "        }\n",
    "        \n",
    "        print(f\"ğŸ† Best prediction selected: {best_coords}\")\n",
    "        print(f\"   Best similarity score: {avg_similarities[best_idx]:.4f}\")\n",
    "        print(f\"   All similarity scores: {avg_similarities}\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# Convenience function for backward compatibility\n",
    "def batch_predict_keyframes(\n",
    "    keyframes_dir: str,\n",
    "    checkpoint_path: str,\n",
    "    device: str = \"cuda\",\n",
    "    index_path: Optional[str] = None,\n",
    "    database_csv_path: str = \"\",\n",
    "    serpapi_key: str = \"\",\n",
    "    imgbb_key: str = \"\",\n",
    "    transcript_file_path: str = \"\",\n",
    "    metadata_file_path: str = \"\",\n",
    "    batch_size: int = 10,\n",
    "    links_per_image: int = 3,\n",
    "    top_k: int = 20,\n",
    "    model_name: str = \"gemini-2.5-flash\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Convenience function for comprehensive batch prediction using the BatchKeyframePredictor class.\n",
    "    \n",
    "    Args:\n",
    "        keyframes_dir (str): Directory containing keyframe/image files\n",
    "        checkpoint_path (str): Path to G3 model checkpoint\n",
    "        device (str): Device to run model on (\"cuda\" or \"cpu\")\n",
    "        index_path (str): Path to FAISS index for RAG (optional)\n",
    "        database_csv_path (str): Path to GPS coordinates database CSV for RAG\n",
    "        serpapi_key (str): SerpAPI key for image search\n",
    "        imgbb_key (str): imgbb API key for image upload\n",
    "        transcript_file_path (str): Path to transcript file\n",
    "        metadata_file_path (str): Path to metadata JSON file\n",
    "        batch_size (int): Number of links to process in each batch (default: 10)\n",
    "        links_per_image (int): Number of search result links to extract per image (default: 3)\n",
    "        top_k (int): Number of top FAISS results for RAG (default: 20)\n",
    "        model_name (str): LLM model name to use\n",
    "        \n",
    "    Returns:\n",
    "        dict: Best prediction with latitude, longitude, location, reason, and metadata\n",
    "    \"\"\"\n",
    "    predictor = BatchKeyframePredictor(\n",
    "        checkpoint_path=checkpoint_path, \n",
    "        device=device,\n",
    "        index_path=index_path\n",
    "    )\n",
    "    return predictor.predict(\n",
    "        keyframes_dir=keyframes_dir,\n",
    "        database_csv_path=database_csv_path,\n",
    "        serpapi_key=serpapi_key,\n",
    "        imgbb_key=imgbb_key,\n",
    "        transcript_file_path=transcript_file_path,\n",
    "        metadata_file_path=metadata_file_path,\n",
    "        batch_size=batch_size,\n",
    "        links_per_image=links_per_image,\n",
    "        top_k=top_k,\n",
    "        model_name=model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0dc2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting comprehensive batch prediction for keyframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tungd\\AppData\\Local\\Temp\\ipykernel_9556\\540956906.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded FAISS index from: index/G3.index\n",
      "ğŸ“ Found 26 image files in C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\n",
      "ğŸ–¼ï¸ Processing image 1/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0000.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0000.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0000.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/ns7kNW1Y/bac1da703780.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/ns7kNW1Y/bac1da703780.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/ns7kNW1Y/bac1da703780.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.rimi.lt/e-parduotuve/en/products/meat-and-fish-/meat-and-poultry-products-/meat-preserves/troskinta-jautiena-biovela-240-g/p/285060 | Title: TroÅ¡kinta jautiena BIOVELA, 240 g\n",
      "ğŸ”— Found candidate: Link: https://www.rimi.lt/e-parduotuve/en/products/meat-and-fish-/meat-and-poultry-products-/meat-preserves/troskinta-kiauliena-biovela-240-g/p/285100 | Title: TroÅ¡kinta kiauliena BIOVELA, 240 g\n",
      "ğŸ”— Found candidate: Link: https://pricer.lt/barboralv/product/sauteta-liellopa-gala-biovela-250g/8947337 | Title: SautÄ“ta liellopa gaÄ¼a BIOVELA 250g\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0000.jpeg\n",
      "ğŸ–¼ï¸ Processing image 2/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0001.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0001.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0001.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/rRZGyKwN/cf1783b3b4b5.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/rRZGyKwN/cf1783b3b4b5.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/rRZGyKwN/cf1783b3b4b5.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.instagram.com/p/DJro-nHIAW8/ | Title: Ñ‚Ğ¾Ñ€ĞµÑ†ÑŒĞº_info ğŸ“² | Â«Ğ”Ğ¶ÑƒÑ€Ğ°Â» Ğ¾Ğ±'Ñ”Ğ´Ğ½ÑƒÑ” ÑĞ½Ğ¸Ñ… Ğ¿Ğ°Ñ‚Ñ€Ñ–Ğ¾Ñ‚Ñ–Ğ² Ğ”Ğ¾Ğ½ĞµÑ‡Ñ‡Ğ¸Ğ½Ğ¸: ÑÑ‚Ğ°Ñ€Ñ‚ÑƒĞ²Ğ°Ğ² Ğ¾Ğ±Ğ»Ğ°ÑĞ½Ğ¸Ğ¹ ĞµÑ‚Ğ°Ğ¿ Ğ³Ñ€Ğ¸ Ğ¡ÑŒĞ¾Ğ³Ğ¾Ğ´Ğ½Ñ– Ğ²Ñ–Ğ´Ğ±ÑƒĞ»Ğ¾ÑÑŒ ÑƒÑ€Ğ¾Ñ‡Ğ¸ÑÑ‚Ğµ Ğ²Ñ–Ğ´ĞºÑ€Ğ¸Ñ‚Ñ‚Ñ Ğ†Ğ† (Ğ¾Ğ±Ğ»Ğ°ÑĞ½Ğ¾Ğ³Ğ¾) ĞµÑ‚Ğ°Ğ¿Ñƒ... | Instagram\n",
      "ğŸ”— Found candidate: Link: https://issuu.com/varlakov/docs/____________ | Title: Issuu\n",
      "ğŸ”— Found candidate: Link: https://www.facebook.com/groups/pereiaslav.dzhura.club/ | Title: ĞŸĞµÑ€ĞµÑÑĞ»Ğ°Ğ²ÑÑŒĞºĞ¸Ğ¹ ĞšĞ»ÑƒĞ± Ğ”Ğ¶ÑƒÑ€Ğ° (pereiaslav.dzhura.club) | Facebook\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0001.jpeg\n",
      "ğŸ–¼ï¸ Processing image 3/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0002.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0002.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0002.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/S4ycNV94/49b700cbc7d5.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/S4ycNV94/49b700cbc7d5.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/S4ycNV94/49b700cbc7d5.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.1tv.ru/news/2022-06-08/430731-vsu_ispolzovali_byvshiy_pionerlager_pod_krasnym_limanom_dlya_ideologicheskoy_obrabotki_shkolnikov | Title: Ğ’Ğ¡Ğ£ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ»Ğ¸ Ğ±Ñ‹Ğ²ÑˆĞ¸Ğ¹ Ğ¿Ğ¸Ğ¾Ğ½ĞµÑ€Ğ»Ğ°Ğ³ĞµÑ€ÑŒ Ğ¿Ğ¾Ğ´ ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¼ Ğ›Ğ¸Ğ¼Ğ°Ğ½Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ¸Ğ´ĞµĞ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ÑˆĞºĞ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ¾Ğ². ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸. ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ°Ğ½Ğ°Ğ»\n",
      "ğŸ”— Found candidate: Link: https://khpg.org/1608809993 | Title: They're killing my father!â€ Daughter of 63-year-old Ukrainian imprisoned for opposing Russian occupation of Crimea\n",
      "ğŸ”— Found candidate: Link: https://khpg.org/en/1601817907 | Title: 62-year-old Ukrainian political prisoner threatens to slash his wrists if Russia doesn't release his medication\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0002.jpeg\n",
      "ğŸ–¼ï¸ Processing image 4/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0003.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0003.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0003.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/jk2GQ3sR/9b9780b81847.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/jk2GQ3sR/9b9780b81847.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/jk2GQ3sR/9b9780b81847.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.couriermail.com.au/news/world/ukraine-commanders-repatriated-to-boost-counter-offensive-as-8-killed-in-russian-missile-attack/news-story/5603999df6c8ce4361b429e4c86940af | Title: Joe Biden lands in UK to meet Rishi Sunak amid concern over Ukraine cluster bombs | The Courier Mail\n",
      "ğŸ”— Found candidate: Link: https://www.outlookindia.com/international/in-pictures-rebuilding-torn-homes-in-ukraine-photos-216458 | Title: In Pictures: Rebuilding Torn Homes In Ukraine\n",
      "ğŸ”— Found candidate: Link: https://x.com/sashagalkin10?lang=ar | Title: Sasha Galkin (@SashaGalkin10) / X\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0003.jpeg\n",
      "ğŸ–¼ï¸ Processing image 5/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0004.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0004.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0004.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/gZL3s13M/2f03d8e3367e.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/gZL3s13M/2f03d8e3367e.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/gZL3s13M/2f03d8e3367e.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.reddit.com/r/UkraineRussiaReport/comments/1jnl7b4/ru_pov_battles_in_belgorod_region_34th_brigade/?tl=es-es | Title: Desde el punto de vista de Rusia: Batallas en la regiÃ³n de Belgorod: la 34Âª brigada destruye a las tropas ucranianas que irrumpieron en Popovka - RVvoenkor : r/UkraineRussiaReport\n",
      "ğŸ”— Found candidate: Link: https://www.avito.ru/chapaevsk/zemelnye_uchastki?context=H4sIAAAAAAAA_wEmANn_YToxOntzOjE6InkiO3M6MTY6InRBaEM5dDBpQXZzMW1mc08iO30LCQHiJgAAAA&p=4 | Title: Ğ—ĞµĞ¼ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‡Ğ°ÑÑ‚ĞºĞ¸ Ğ² Ğ§Ğ°Ğ¿Ğ°ĞµĞ²ÑĞºĞµ: Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ° Ğ¸ Ğ°Ñ€ĞµĞ½Ğ´Ğ°| ĞĞ²Ğ¸Ñ‚Ğ¾\n",
      "ğŸ”— Found candidate: Link: https://www.avito.ru/muslyumovo/doma_dachi_kottedzhi/prodam/street/ulitsa_neftyanikov/766362-ASgBAgECAkSUA9AQ6MgTtMZdAUW6GBQidWxpdHNhX25lZnR5YW5pa292Ig?context= | Title: ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ° Ğ´Ğ¾Ğ¼Ğ¾Ğ², Ğ´Ğ°Ñ‡, ĞºĞ¾Ñ‚Ñ‚ĞµĞ´Ğ¶ĞµĞ¹, Ñ‚Ğ°ÑƒĞ½Ñ…Ğ°ÑƒÑĞ¾Ğ² Ğ¿Ğ¾ Ğ°Ğ´Ñ€ĞµÑÑƒ ÑƒĞ»Ğ¸Ñ†Ğ° ĞĞµÑ„Ñ‚ÑĞ½Ğ¸ĞºĞ¾Ğ² Ğ² ĞœÑƒÑĞ»ÑĞ¼Ğ¾Ğ²Ğ¾: 1 Ğ¾Ğ±ÑŠÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° ĞĞ²Ğ¸Ñ‚Ğ¾\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0004.jpeg\n",
      "ğŸ–¼ï¸ Processing image 6/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0005.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0005.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0005.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/N26x81cJ/dbd944c8066b.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/N26x81cJ/dbd944c8066b.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/N26x81cJ/dbd944c8066b.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.instagram.com/volodymyr_doliak/ | Title: Ğ’Ğ¾Ğ»Ğ¾Ğ´Ğ¸Ğ¼Ğ¸Ñ€ Ğ”Ğ¾Ğ»ÑĞº (@volodymyr_doliak) Â· Instagram photos and Reels\n",
      "ğŸ”— Found candidate: Link: https://www.youtube.com/shorts/p09NQDqA_Ws | Title: Ğ”ÑĞºÑƒÑ”Ğ¼Ğ¾ #shorts #youtubeshorts #music #youtube #Ğ·ÑÑƒ #army - YouTube\n",
      "ğŸ”— Found candidate: Link: https://x.com/ukrainiansquad/status/1811813473632027010 | Title: UKRAINIAN SQUADğŸ‡ºğŸ‡¦ on X: \"Write your country name if you still SUPPORT Ukraine and these Soldiersâ¤ï¸ https://t.co/H48xm12lEV\" / X\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0005.jpeg\n",
      "ğŸ–¼ï¸ Processing image 7/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0006.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0006.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0006.jpeg\n",
      "âœ… Image uploaded successfully: https://i.ibb.co/0yDV0xVg/321a0639e034.jpg\n",
      "ğŸ” Searching with SerpAPI...\n",
      "   Engine: google_lens\n",
      "   Text query: \n",
      "   Image URL: https://i.ibb.co/0yDV0xVg/321a0639e034.jpg\n",
      "ğŸŒ SerpAPI request params: {'engine': 'google_lens', 'api_key': 'f2dd682a8ba4e1b8c2c6ade0439a427dbf4dca7e8510e2c5d17495e7cb88bd84', 'url': 'https://i.ibb.co/0yDV0xVg/321a0639e034.jpg'}\n",
      "âœ… Search completed successfully\n",
      "ğŸ”— Found candidate: Link: https://www.youtube.com/watch?v=GVJB0J54OZ0 | Title: Tatjana Kolobaric 01022019 - YouTube\n",
      "ğŸ”— Found candidate: Link: https://www.flickr.com/photos/oscepa/50285899831 | Title: Kristian Jensen (Denmark) observing elections in Montenegrâ€¦ | Flickr\n",
      "ğŸ”— Found candidate: Link: https://x.com/NasirKhanUKPNP/status/1937784471207735491 | Title: Sardar Nasir Aziz KHAN on X: \"#UKPNP Seminar on Pathways to peace, security, & fundamental rights in #JammuKashmir begin with unification, addressing the root causes & grievances of its natives.Justice for #ZarnoshNasim #\n",
      "âœ… Found 3 web candidates for 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0006.jpeg\n",
      "ğŸ–¼ï¸ Processing image 8/26: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0007.jpeg\n",
      "ğŸ” Searching FAISS index for RAG coordinates...\n",
      "Searching FAISS index...\n",
      "ï¿½ Found 20 candidate GPS and 20 reverse GPS coordinates\n",
      "ï¿½ğŸ” Searching web for image: 3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0007.jpeg\n",
      "ğŸ” Search mode: Image + Text\n",
      "ğŸš€ Using engine: google_lens\n",
      "ğŸ“¤ Uploading image to imgbb: C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\\3660eb4aed1548c7bb8a8dc305d9a4c3_kf_0007.jpeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Method 1: Using the class directly (recommended for comprehensive features)\u001b[39;00m\n\u001b[32m     24\u001b[39m predictor = BatchKeyframePredictor(\n\u001b[32m     25\u001b[39m     checkpoint_path=checkpoint_path,\n\u001b[32m     26\u001b[39m     device=device,\n\u001b[32m     27\u001b[39m     index_path=index_path  \u001b[38;5;66;03m# Enable RAG with FAISS index\u001b[39;00m\n\u001b[32m     28\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m result = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyframes_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeyframes_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase_csv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GPS database for RAG\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserpapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserpapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgbb_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimgbb_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtranscript_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtranscript_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Audio context\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Video metadata\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlinks_per_image\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinks_per_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ‰ Comprehensive batch prediction completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“ Predicted Location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 469\u001b[39m, in \u001b[36mBatchKeyframePredictor.predict\u001b[39m\u001b[34m(self, keyframes_dir, database_csv_path, serpapi_key, imgbb_key, transcript_file_path, metadata_file_path, batch_size, links_per_image, top_k, model_name)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# Perform image search for web candidates\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mï¿½ğŸ” Searching web for image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m search_results = \u001b[43msearch_with_image_and_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43msearch_text\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Image-only search\u001b[39;49;00m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserpapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserpapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgbb_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimgbb_key\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# Extract candidate links\u001b[39;00m\n\u001b[32m    477\u001b[39m search_candidates = extract_image_search_candidates(\n\u001b[32m    478\u001b[39m     search_results, \n\u001b[32m    479\u001b[39m     no_results=links_per_image\n\u001b[32m    480\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\utils\\utils.py:154\u001b[39m, in \u001b[36msearch_with_image_and_text\u001b[39m\u001b[34m(image_path, search_text, serpapi_key, imgbb_key, engine)\u001b[39m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mimgbb_key is required when image_path is provided\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“¤ Uploading image to imgbb: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     image_url = \u001b[43mupload_image_to_imgbb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgbb_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Image uploaded successfully: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# Validate inputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\utils\\utils.py:81\u001b[39m, in \u001b[36msearch_with_image_and_text.<locals>.upload_image_to_imgbb\u001b[39m\u001b[34m(image_path, api_key)\u001b[39m\n\u001b[32m     75\u001b[39m payload = {\n\u001b[32m     76\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m'\u001b[39m: api_key,\n\u001b[32m     77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m: image_data\n\u001b[32m     78\u001b[39m }\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgbb_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     response.raise_for_status()\n\u001b[32m     84\u001b[39m     result = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\myenv\\Lib\\site-packages\\urllib3\\connection.py:459\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    457\u001b[39m             \u001b[38;5;28mself\u001b[39m.send(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%x\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33mb\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mlen\u001b[39m(chunk), chunk))\n\u001b[32m    458\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;66;03m# Regardless of whether we have a body or not, if we're in\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# chunked mode we want to send an explicit empty chunk.\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunked:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1009\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1007\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.send\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, data)\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections.abc.Iterable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1274\u001b[39m, in \u001b[36mSSLSocket.sendall\u001b[39m\u001b[34m(self, data, flags)\u001b[39m\n\u001b[32m   1272\u001b[39m         amount = \u001b[38;5;28mlen\u001b[39m(byte_view)\n\u001b[32m   1273\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m count < amount:\n\u001b[32m-> \u001b[39m\u001b[32m1274\u001b[39m             v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1275\u001b[39m             count += v\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1243\u001b[39m, in \u001b[36mSSLSocket.send\u001b[39m\u001b[34m(self, data, flags)\u001b[39m\n\u001b[32m   1239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1240\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1241\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to send() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1242\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.write(data)\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().send(data, flags)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "keyframes_dir = r\"C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\katna_keyframes\\ID115\"\n",
    "checkpoint_path = \"checkpoints/mercator_finetune_weight.pth\"\n",
    "index_path = \"index/G3.index\"  # FAISS index for RAG\n",
    "database_csv_path = \"data/mp16/MP16_Pro_filtered.csv\"  # GPS database for RAG\n",
    "device = \"cuda\"  if torch.cuda.is_available() else \"cpu\"  # Use GPU if available\n",
    "\n",
    "# Optional context files\n",
    "transcript_file_path = r\"C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\G3-Original\\g3\\data\\batch_processing\\combined_transcript.txt\"  # Audio transcript (optional)\n",
    "metadata_file_path = r\"C:\\Users\\tungd\\OneDrive - MSFT\\Second Year\\ML\\ACMMM25 - Grand Challenge on Multimedia Verification\\dataset\\validation\\ID115\\ID115\\input\\ID115.json\"    # Video metadata (optional)\n",
    "\n",
    "# API keys (can also be set as environment variables)\n",
    "serpapi_key = os.getenv(\"SERPAPI_KEY\", \"\")\n",
    "imgbb_key = os.getenv(\"IMGBB_KEY\", \"\")\n",
    "\n",
    "# Processing parameters\n",
    "batch_size = 10  # Process 10 links at a time\n",
    "links_per_image = 3  # Extract 3 search result links per image\n",
    "top_k = 20  # Top 20 FAISS results for RAG\n",
    "\n",
    "try:\n",
    "    print(\"ğŸš€ Starting comprehensive batch prediction for keyframes...\")\n",
    "    \n",
    "    # Method 1: Using the class directly (recommended for comprehensive features)\n",
    "    predictor = BatchKeyframePredictor(\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        device=device,\n",
    "        index_path=index_path  # Enable RAG with FAISS index\n",
    "    )\n",
    "    \n",
    "    result = predictor.predict(\n",
    "        keyframes_dir=keyframes_dir,\n",
    "        database_csv_path=database_csv_path,  # GPS database for RAG\n",
    "        serpapi_key=serpapi_key,\n",
    "        imgbb_key=imgbb_key,\n",
    "        transcript_file_path=transcript_file_path,  # Audio context\n",
    "        metadata_file_path=metadata_file_path,      # Video metadata\n",
    "        batch_size=batch_size,\n",
    "        links_per_image=links_per_image,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    \n",
    "    print(\"\\nğŸ‰ Comprehensive batch prediction completed successfully!\")\n",
    "    print(f\"ğŸ“ Predicted Location: {result['latitude']}, {result['longitude']}\")\n",
    "    print(f\"ğŸ“‹ Place: {result['location']}\")\n",
    "    print(f\"ğŸ’­ Reasoning: {result['reason']}\")\n",
    "    \n",
    "    # Print comprehensive metadata\n",
    "    metadata = result['metadata']\n",
    "    print(f\"\\nğŸ“Š Processing Statistics:\")\n",
    "    print(f\"   â€¢ Images processed: {metadata['num_images_processed']}\")\n",
    "    print(f\"   â€¢ Unique web links: {metadata['num_unique_links']}\")\n",
    "    print(f\"   â€¢ RAG candidate coordinates: {metadata['num_rag_candidates']}\")\n",
    "    print(f\"   â€¢ RAG reverse coordinates: {metadata['num_rag_reverse']}\")\n",
    "    print(f\"   â€¢ Valid predictions: {metadata['num_predictions']}\")\n",
    "    print(f\"   â€¢ Best similarity score: {metadata['best_similarity_score']:.4f}\")\n",
    "    print(f\"   â€¢ Processing mode: {metadata['processing_mode']}\")\n",
    "    print(f\"   â€¢ Has FAISS index: {metadata['has_faiss_index']}\")\n",
    "    \n",
    "    # Show RAG coordinates info\n",
    "    if metadata['num_rag_candidates'] > 0:\n",
    "        rag_coords = metadata['rag_coordinates']\n",
    "        print(f\"\\nğŸ“ RAG Coordinates Summary:\")\n",
    "        print(f\"   â€¢ Sample candidate GPS: {rag_coords['candidates_gps'][:3]}\")\n",
    "        print(f\"   â€¢ Sample reverse GPS: {rag_coords['reverse_gps'][:3]}\")\n",
    "    \n",
    "    # Show web candidates info\n",
    "    if metadata['num_unique_links'] > 0:\n",
    "        candidates_dict = metadata['candidates_dict']\n",
    "        print(f\"\\nğŸ”— Web Candidates Summary:\")\n",
    "        for i, (link, candidate) in enumerate(list(candidates_dict.items())[:3]):\n",
    "            print(f\"   {i+1}. {candidate[:100]}...\")\n",
    "    \n",
    "    # Show context files used\n",
    "    print(f\"\\nğŸ“‚ Context Files Used:\")\n",
    "    print(f\"   â€¢ Database CSV: {metadata['database_csv_path'] or 'None'}\")\n",
    "    print(f\"   â€¢ Transcript: {metadata['transcript_file_path'] or 'None'}\")\n",
    "    print(f\"   â€¢ Metadata: {metadata['metadata_file_path'] or 'None'}\")\n",
    "    \n",
    "    # Save result to file\n",
    "    import json\n",
    "    output_file = \"comprehensive_batch_prediction_result.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    print(f\"ğŸ’¾ Detailed result saved to: {output_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error during comprehensive batch prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a6a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
